{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_cleaner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8kH8ag5q__m"
      },
      "outputs": [],
      "source": [
        "def features_from_bool_to_binary(df, features=['is_user_logged_in', 'is_first_booking']):\n",
        "    for feature in features:\n",
        "        df[feature] = self.df[feature].astype(int)\n",
        "\n",
        "def time_delta(df, col1, col2, new_name, format='days'):\n",
        "  time_delta_series  = pd.to_datetime(df[col2])-pd.to_datetime(df[col1])\n",
        "  if format=='days':\n",
        "    df[new_name] = time_delta_series.dt.days\n",
        "  elif format=='months':\n",
        "    df[new_name] = time_delta_series.dt.months\n",
        "  elif format == 'years':\n",
        "    df[new_name] = time_delta_series.dt.years\n",
        "\n",
        "def fill_na(df, columns, val):\n",
        "  df[columns] = df[columns].fillna(val)\n",
        "\n",
        "def func_on_cols(df, columns, new_name, func):\n",
        "  df['new_name']= func([df[col_name] for col_name in columns])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "large categories to groups (by cancellation rate)"
      ],
      "metadata": {
        "id": "m4E8gjoZsvzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_NUM_APEARENCESS = 5\n",
        "large_cat_cols = []\n",
        "for col in large_cat_cols:\n",
        "  df[f'{col}_cancellation_rate'] = df[TARGET].groupby(df[col]).transform('mean')\n",
        "  vc = df[col].value_counts()\n",
        "  bad_values = list(vc[vc <= MIN_NUM_APEARENCESS].index) #not enough appearances\n",
        "  df.loc[[i in bad_values for i in df[col]], f'{col}_cancellation_rate'] = 0.5\n",
        "\n",
        "\n",
        "def large_cat_to_groups(large_cat_cols=[],\n",
        "                          min_num_apearencess=5):\n",
        "    if self.is_train:\n",
        "        for col in large_cat_cols:\n",
        "            self.df[f'{col}_cancellation_rate'] = self.df[self.target].groupby(self.df[col], sort=False).transform('mean')\n",
        "            vc = self.df[col].value_counts()    \n",
        "            bad_values = list(vc[vc <= min_num_apearencess].index)  # not enough appearances\n",
        "            self.df.loc[[i in bad_values for i in self.df[col]], f'{col}_cancellation_rate'] = 0.5\n",
        "            gb = self.df[self.target].groupby(self.df[col], sort=False).mean()\n",
        "            self.mappers[col] = gb.to_dict()\n",
        "    else:\n",
        "        for col in large_cat_cols:\n",
        "            self.df[f'{col}_cancellation_rate'] = self.df[col].map(self.mappers[col])"
      ],
      "metadata": {
        "id": "bZSkiOt7swPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}